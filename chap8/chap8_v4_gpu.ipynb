{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75dad6f6-2805-4cad-b335-1bf3384033f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils\n",
    "import PIL\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import d2l\n",
    "from d2l import torch as d2l\n",
    "from IPython import display\n",
    "import datetime\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torchvision as tv\n",
    "from collections import OrderedDict\n",
    "\n",
    "import requests\n",
    "import io\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8337080e-312c-4d0c-8aa4-cd6795ad6a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Downloading CIFAR-10\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True) #下载太慢请开代理\n",
    "\n",
    "# 引入normalize的数据初始化\n",
    "tensor_cifar10_normalize_train = datasets.CIFAR10(data_path, train=True, download=False,\n",
    "                            transform = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                                                     (0.2470, 0.2435, 0.2616))\n",
    "                            ]))\n",
    "\n",
    "tensor_cifar10_normalize_val = datasets.CIFAR10(data_path, train=False, download=False,\n",
    "                            transform = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                                                     (0.2470, 0.2435, 0.2616))\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6d55ca0-33ed-4c9e-9006-81747d07605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dataset and DataLoader\n",
    "label_map = {0: 0, 2: 1} # 占位符\n",
    "class_names = ['airplane', 'bird']\n",
    "# 训练集\n",
    "cifar2 = [(img, label_map[label])\n",
    "    for img, label in tensor_cifar10_normalize_train\n",
    "        if label in [0, 2]]\n",
    "# 验证集\n",
    "cifar2_val = [(img, label_map[label])\n",
    "   for img, label in tensor_cifar10_normalize_val\n",
    "      if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9699c19f-63d4-4e70-b64e-b9edd1fb0a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "  else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee93428d-d6c0-49c3-b186-42b0528791bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "          imgs = imgs.to(device)\n",
    "          labels = labels.to(device)\n",
    "          outputs = model(imgs)\n",
    "          loss = loss_fn(outputs, labels)\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(datetime.datetime.now(), epoch, loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aad964e8-5289-475a-894a-bb44c5db333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.4.1 Measuring accuracy\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f883e75-19aa-4be1-9891-89f47562475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StdConv2d(nn.Conv2d):\n",
    "\n",
    "    def forward(self, x):\n",
    "        w = self.weight\n",
    "        v, m = torch.var_mean(w, dim=[1, 2, 3], keepdim=True, unbiased=False)\n",
    "        w = (w - m) / torch.sqrt(v + 1e-10)\n",
    "        return F.conv2d(x, w, self.bias, self.stride, self.padding, self.dilation, self.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5692127-56cd-4474-b66c-958699ae9953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(cin, cout, stride=1, groups=1, bias=False):\n",
    "    return StdConv2d(cin, cout, kernel_size=3, stride=stride, padding=1, bias=bias, groups=groups)\n",
    "\n",
    "def conv1x1(cin, cout, stride=1, bias=False):\n",
    "    return StdConv2d(cin, cout, kernel_size=1, stride=stride, padding=0, bias=bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab49220e-0d47-4537-82d8-382de4259c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf2th(conv_weights):\n",
    "    \"\"\"Possibly convert HWIO to OIHW.\"\"\"\n",
    "    if conv_weights.ndim == 4:\n",
    "        conv_weights = conv_weights.transpose([3, 2, 0, 1])\n",
    "    return torch.from_numpy(conv_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5234f7f-d65f-487f-9279-0a4f27c1bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreActBottleneck(nn.Module):\n",
    "    \n",
    "    def __init__(self, cin, cout=None, cmid=None, stride=1):\n",
    "        super().__init__()\n",
    "        cout = cout or cin\n",
    "        cmid = cmid or cout//4\n",
    "\n",
    "        self.gn1 = nn.GroupNorm(32, cin)\n",
    "        self.conv1 = conv1x1(cin, cmid)\n",
    "        self.gn2 = nn.GroupNorm(32, cmid)\n",
    "        self.conv2 = conv3x3(cmid, cmid, stride)  # Original code has it on conv1!!\n",
    "        self.gn3 = nn.GroupNorm(32, cmid)\n",
    "        self.conv3 = conv1x1(cmid, cout)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if (stride != 1 or cin != cout):\n",
    "          # Projection also with pre-activation according to paper.\n",
    "          self.downsample = conv1x1(cin, cout, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.gn1(x))\n",
    "\n",
    "        # Residual branch\n",
    "        residual = x\n",
    "        if hasattr(self, 'downsample'):\n",
    "            residual = self.downsample(out)\n",
    "\n",
    "        # Unit's branch\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(self.relu(self.gn2(out)))\n",
    "        out = self.conv3(self.relu(self.gn3(out)))\n",
    "\n",
    "        return out + residual\n",
    "\n",
    "    def load_from(self, weights, prefix=''):\n",
    "        convname = 'standardized_conv2d'\n",
    "        with torch.no_grad():\n",
    "            self.conv1.weight.copy_(tf2th(weights[f'{prefix}a/{convname}/kernel']))\n",
    "            self.conv2.weight.copy_(tf2th(weights[f'{prefix}b/{convname}/kernel']))\n",
    "            self.conv3.weight.copy_(tf2th(weights[f'{prefix}c/{convname}/kernel']))\n",
    "            self.gn1.weight.copy_(tf2th(weights[f'{prefix}a/group_norm/gamma']))\n",
    "            self.gn2.weight.copy_(tf2th(weights[f'{prefix}b/group_norm/gamma']))\n",
    "            self.gn3.weight.copy_(tf2th(weights[f'{prefix}c/group_norm/gamma']))\n",
    "            self.gn1.bias.copy_(tf2th(weights[f'{prefix}a/group_norm/beta']))\n",
    "            self.gn2.bias.copy_(tf2th(weights[f'{prefix}b/group_norm/beta']))\n",
    "            self.gn3.bias.copy_(tf2th(weights[f'{prefix}c/group_norm/beta']))\n",
    "            if hasattr(self, 'downsample'):\n",
    "                self.downsample.weight.copy_(tf2th(weights[prefix + 'a/proj/standardized_conv2d/kernel']))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a4a9275-c9e5-4d52-ab38-90ea381e9960",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetV2(nn.Module):\n",
    "    BLOCK_UNITS = {\n",
    "      'r50': [3, 4, 6, 3],\n",
    "      'r101': [3, 4, 23, 3],\n",
    "      'r152': [3, 8, 36, 3],\n",
    "    }\n",
    "\n",
    "    def __init__(self, block_units, width_factor, head_size=21843, zero_head=False):\n",
    "        super().__init__()\n",
    "        wf = width_factor  # shortcut 'cause we'll use it a lot.\n",
    "\n",
    "        self.root = nn.Sequential(OrderedDict([\n",
    "            ('conv', StdConv2d(3, 64*wf, kernel_size=7, stride=2, padding=3, bias=False)),\n",
    "            ('padp', nn.ConstantPad2d(1, 0)),\n",
    "            ('pool', nn.MaxPool2d(kernel_size=3, stride=2, padding=0)),\n",
    "            # The following is subtly not the same!\n",
    "            #('pool', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
    "        ]))\n",
    "\n",
    "        self.body = nn.Sequential(OrderedDict([\n",
    "            ('block1', nn.Sequential(OrderedDict(\n",
    "                [('unit01', PreActBottleneck(cin= 64*wf, cout=256*wf, cmid=64*wf))] +\n",
    "                [(f'unit{i:02d}', PreActBottleneck(cin=256*wf, cout=256*wf, cmid=64*wf)) for i in range(2, block_units[0] + 1)],\n",
    "            ))),\n",
    "            ('block2', nn.Sequential(OrderedDict(\n",
    "                [('unit01', PreActBottleneck(cin=256*wf, cout=512*wf, cmid=128*wf, stride=2))] +\n",
    "                [(f'unit{i:02d}', PreActBottleneck(cin=512*wf, cout=512*wf, cmid=128*wf)) for i in range(2, block_units[1] + 1)],\n",
    "            ))),\n",
    "            ('block3', nn.Sequential(OrderedDict(\n",
    "                [('unit01', PreActBottleneck(cin= 512*wf, cout=1024*wf, cmid=256*wf, stride=2))] +\n",
    "                [(f'unit{i:02d}', PreActBottleneck(cin=1024*wf, cout=1024*wf, cmid=256*wf)) for i in range(2, block_units[2] + 1)],\n",
    "            ))),\n",
    "            ('block4', nn.Sequential(OrderedDict(\n",
    "                [('unit01', PreActBottleneck(cin=1024*wf, cout=2048*wf, cmid=512*wf, stride=2))] +\n",
    "                [(f'unit{i:02d}', PreActBottleneck(cin=2048*wf, cout=2048*wf, cmid=512*wf)) for i in range(2, block_units[3] + 1)],\n",
    "            ))),\n",
    "        ]))\n",
    "\n",
    "        self.zero_head = zero_head\n",
    "        self.head = nn.Sequential(OrderedDict([\n",
    "            ('gn', nn.GroupNorm(32, 2048*wf)),\n",
    "            ('relu', nn.ReLU(inplace=True)),\n",
    "            ('avg', nn.AdaptiveAvgPool2d(output_size=1)),\n",
    "            ('conv', nn.Conv2d(2048*wf, head_size, kernel_size=1, bias=True)),\n",
    "        ]))\n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = self.head(self.body(self.root(x)))\n",
    "        assert x.shape[-2:] == (1, 1)  # We should have no spatial shape left.\n",
    "        return x[...,0,0]\n",
    "\n",
    "    def load_from(self, weights, prefix='resnet/'):\n",
    "        with torch.no_grad():\n",
    "            self.root.conv.weight.copy_(tf2th(weights[f'{prefix}root_block/standardized_conv2d/kernel']))\n",
    "            self.head.gn.weight.copy_(tf2th(weights[f'{prefix}group_norm/gamma']))\n",
    "            self.head.gn.bias.copy_(tf2th(weights[f'{prefix}group_norm/beta']))\n",
    "            if self.zero_head:\n",
    "                nn.init.zeros_(self.head.conv.weight)\n",
    "                nn.init.zeros_(self.head.conv.bias)\n",
    "            else:\n",
    "                self.head.conv.weight.copy_(tf2th(weights[f'{prefix}head/conv2d/kernel']))\n",
    "                self.head.conv.bias.copy_(tf2th(weights[f'{prefix}head/conv2d/bias']))\n",
    "\n",
    "            for bname, block in self.body.named_children():\n",
    "                for uname, unit in block.named_children():\n",
    "                    unit.load_from(weights, prefix=f'{prefix}{bname}/{uname}/')\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4d2bba3-1f2b-4fbd-80e6-b7da5a7398c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(bit_variant):\n",
    "    response = requests.get(f'https://storage.googleapis.com/bit_models/{bit_variant}.npz')\n",
    "    response.raise_for_status()\n",
    "    return np.load(io.BytesIO(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f44bf90-6c5a-4e06-a38b-89567687c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_cifar10 = get_weights('BiT-M-R50x1-CIFAR10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7067526-597f-4124-970c-822b5f96a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "        print(\"Accuracy {}: {:.4f}\".format(name , correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58f64a97-473b-4e50-bc34-24de98a4d6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-25 01:26:06.931912 Epoch 1, Training loss 0.41381569009772534\n",
      "2021-10-25 01:30:35.274021 Epoch 10, Training loss 0.006827643942409514\n",
      "2021-10-25 01:35:33.052661 Epoch 20, Training loss 1.2998311097791281e-05\n",
      "Accuracy train: 1.0000\n",
      "Accuracy val: 0.9585\n"
     ]
    }
   ],
   "source": [
    "# Big_transfer\n",
    "model = ResNetV2(ResNetV2.BLOCK_UNITS['r50'], width_factor=1, head_size=10).to(device=device)  # NOTE: No new head.\n",
    "model.load_from(weights_cifar10)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "  n_epochs = 20,\n",
    "  optimizer = optimizer,\n",
    "  model = model,\n",
    "  loss_fn = loss_fn,\n",
    "  train_loader = train_loader,\n",
    ")\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3053a3f-7daf-40d5-b908-df3582c691f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetV2(\n",
       "  (root): Sequential(\n",
       "    (conv): StdConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (padp): ConstantPad2d(padding=(1, 1, 1, 1), value=0)\n",
       "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (body): Sequential(\n",
       "    (block1): Sequential(\n",
       "      (unit01): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (unit02): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit03): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (unit01): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): StdConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (unit02): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit03): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit04): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block3): Sequential(\n",
       "      (unit01): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): StdConv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (unit02): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit03): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit04): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit05): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit06): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block4): Sequential(\n",
       "      (unit01): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): StdConv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (unit02): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit03): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (gn): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avg): AdaptiveAvgPool2d(output_size=1)\n",
       "    (conv): Conv2d(2048, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
