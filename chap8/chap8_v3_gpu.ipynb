{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b8c929e-26f6-4a28-9596-f7e62494ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils\n",
    "import PIL\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import d2l\n",
    "from d2l import torch as d2l\n",
    "from IPython import display\n",
    "import datetime\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304f89f7-1d6e-438a-b55a-aeca13056345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Downloading CIFAR-10\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True) #下载太慢请开代理\n",
    "\n",
    "# 引入normalize的数据初始化\n",
    "tensor_cifar10_normalize_train = datasets.CIFAR10(data_path, train=True, download=False,\n",
    "                            transform = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                                                     (0.2470, 0.2435, 0.2616))\n",
    "                            ]))\n",
    "\n",
    "tensor_cifar10_normalize_val = datasets.CIFAR10(data_path, train=False, download=False,\n",
    "                            transform = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                                                     (0.2470, 0.2435, 0.2616))\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70e1c1bf-c77a-443b-89ab-4e18bfe3ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dataset and DataLoader\n",
    "label_map = {0: 0, 2: 1} # 占位符\n",
    "class_names = ['airplane', 'bird']\n",
    "# 训练集\n",
    "cifar2 = [(img, label_map[label])\n",
    "    for img, label in tensor_cifar10_normalize_train\n",
    "        if label in [0, 2]]\n",
    "# 验证集\n",
    "cifar2_val = [(img, label_map[label])\n",
    "   for img, label in tensor_cifar10_normalize_val\n",
    "      if label in [0, 2]]\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a049c4ec-a113-4099-a814-3f014126deda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用torch.nn.functional实现更简洁的定义网络的方法\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04bc0515-4565-4766-86b0-598c091bca88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "  else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40cb8793-7bfe-4ce9-8c83-f7d81bdfc4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "          imgs = imgs.to(device)\n",
    "          labels = labels.to(device)\n",
    "          outputs = model(imgs)\n",
    "          loss = loss_fn(outputs, labels)\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(datetime.datetime.now(), epoch, loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c40de6ac-f988-4f5b-a88b-02034cf97837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.4.1 Measuring accuracy\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "577580de-4471-46e8-a7d5-d3e8c79f9e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# training_loop(\n",
    "#   n_epochs = 100,\n",
    "#   optimizer = optimizer,\n",
    "#   model = model,\n",
    "#   loss_fn = loss_fn,\n",
    "#   train_loader = train_loader,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50b7a31c-951a-4e80-8b18-9f1b301a7b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "        print(\"Accuracy {}: {:.4f}\".format(name , correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4019b963-e3f9-4ae9-8afa-276e32d0781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bfeffca-bfc6-4dc6-87dd-8d2f7085bfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load model\n",
    "torch.save(model.state_dict(), data_path + 'birds_vs_airplanes.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0934e8bc-46b9-4baf-bb9f-693802f8b575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cpu加载\n",
    "loaded_model = Net()\n",
    "loaded_model.load_state_dict(torch.load(data_path + 'birds_vs_airplanes.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef98a361-3058-4d92-abfa-ddce11e79b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gpu加载\n",
    "loaded_model = Net().to(device=device)\n",
    "loaded_model.load_state_dict(torch.load(data_path + 'birds_vs_airplanes.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2df041ef-59a7-4148-9cd4-8210a490f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5 Adding memory capacity: Width\n",
    "class NetWidth(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 16, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(16 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 16 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "567e8566-1abb-4e9b-8f30-e996314d40db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid hardcoding numbers,pass parameters use init\n",
    "class NetWidth(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b64e88ce-6a69-4169-b2f8-fae23c3b1743",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "                    nn.Conv2d(3, 32, kernel_size=3, padding=1), nn.Tanh(),\n",
    "                    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                    nn.Conv2d(32, 16, kernel_size=3, padding=1), nn.Tanh(),\n",
    "                    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(16 * 8 * 8, 32), nn.Tanh(),\n",
    "                    nn.Linear(32,2)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5e19bd6-861c-4e8d-be90-f337341f6827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d Output shape:\t torch.Size([3, 32, 32, 32])\n",
      "Tanh Output shape:\t torch.Size([3, 32, 32, 32])\n",
      "MaxPool2d Output shape:\t torch.Size([3, 32, 16, 16])\n",
      "Conv2d Output shape:\t torch.Size([3, 16, 16, 16])\n",
      "Tanh Output shape:\t torch.Size([3, 16, 16, 16])\n",
      "MaxPool2d Output shape:\t torch.Size([3, 16, 8, 8])\n",
      "Flatten Output shape:\t torch.Size([3, 1024])\n",
      "Linear Output shape:\t torch.Size([3, 32])\n",
      "Tanh Output shape:\t torch.Size([3, 32])\n",
      "Linear Output shape:\t torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "#查看每层卷积的形状\n",
    "X = torch.rand(3,3,32,32)\n",
    "for layer in net:\n",
    "    X=layer(X)\n",
    "    print(layer.__class__.__name__,'Output shape:\\t',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66470317-e57c-4610-9f96-895c3a13a65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18090"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#计算模型中所有参数的数目\n",
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "252b2d7f-be1b-4005-b8f4-8780a47a0c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetWidth(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=1024, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = NetWidth()\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c1ef6a2-aa33-49f7-971f-b95d9b41f141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38386"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "036c4d5f-dd90-49f1-9c2f-1bbbfd70861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5.2 Helping our model to converge and generalize: Regularization\n",
    "# L2正则化\n",
    "def training_loop_l2reg(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            l2_lambda = 0.001\n",
    "            l2_norm = sum(p.pow(2.0).sum()\n",
    "        for p in model.parameters())\n",
    "            loss = loss + l2_lambda * l2_norm\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(datetime.datetime.now(), epoch, loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba791404-f8d7-4f4c-92f6-a3619c706def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DropOut\n",
    "class NetDropout(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv1_dropout = nn.Dropout2d(p=0.4)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.conv2_dropout = nn.Dropout2d(p=0.4)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = self.conv1_dropout(out)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = self.conv2_dropout(out)\n",
    "        out = out.view(-1,8*8* self.n_chans1 // 2)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff94767d-5a2a-4e64-815a-39061a1f01eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetDropout(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_dropout): Dropout2d(p=0.4, inplace=False)\n",
       "  (conv2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_dropout): Dropout2d(p=0.4, inplace=False)\n",
       "  (fc1): Linear(in_features=1024, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NetDropout()\n",
    "model.train()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea887cdd-e2fc-4f15-be03-51decfb782e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH NORMALIZATION\n",
    "class NetBatchNorm(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv1_batchnorm = nn.BatchNorm2d(num_features=n_chans1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.conv2_batchnorm = nn.BatchNorm2d(num_features=n_chans1 // 2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1_batchnorm(self.conv1(x))\n",
    "        out = F.max_pool2d(torch.tanh(out), 2)\n",
    "        out = self.conv2_batchnorm(self.conv2(out))\n",
    "        out = F.max_pool2d(torch.tanh(out), 2)\n",
    "        out = out.view(-1,8*8* self.n_chans1 // 2)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d0aa7c6-64a8-4538-be59-a887be930168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetBatchNorm(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=1024, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NetBatchNorm()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb81db12-34bc-4855-b0c0-d12a9901f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetDepth(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)), 2)\n",
    "        out = out.view(-1,4*4* self.n_chans1 // 2)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c6cf00f-f7fb-4b66-8707-3394f041e714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetDepth(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NetDepth()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40fdcb15-f361-4115-a179-3d25755e4bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet残差网络\n",
    "class NetRes(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out1 = out\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)) + out1, 2)\n",
    "        out = out.view(-1,4*4* self.n_chans1 // 2)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4dffc6f-2f40-465a-855b-75b5bba87245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetRes(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NetRes()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7908d265-b57c-4182-8802-8a5d368e3d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个ResNet Bolck\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3, padding=1, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight, nonlinearity='relu')\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68dc3120-5a47-4012-98b3-b2da8f0c4463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResBlock(\n",
       "  (conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batch_norm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResBlock(3)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ba6a19d-bc45-4e9e-b8f5-01dcce30a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过堆叠resnet-block实现深度ResNet网络\n",
    "class NetResDeep(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.resblocks = nn.Sequential(\n",
    "        *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1,8*8* self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6500c2e-76d5-4978-86dd-1aaa54dbe2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetResDeep(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (resblocks): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): ResBlock(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): ResBlock(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): ResBlock(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): ResBlock(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): ResBlock(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): ResBlock(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): ResBlock(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=2048, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NetResDeep()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eef0f662-c0dd-40cd-ae3a-3e89a7f54c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5.4 Comparing the designs from this section\n",
    "# 对比不同架构网络的优劣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8219b29-ce8e-4dd6-b0f0-951857af6940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-24 09:08:58.274755 Epoch 1, Training loss 0.5824292490057125\n",
      "2021-10-24 09:09:04.379817 Epoch 10, Training loss 0.34009778974162547\n",
      "2021-10-24 09:09:10.787169 Epoch 20, Training loss 0.29815340820391467\n",
      "2021-10-24 09:09:17.379319 Epoch 30, Training loss 0.27077277759268026\n",
      "2021-10-24 09:09:24.030786 Epoch 40, Training loss 0.2498732055922982\n",
      "2021-10-24 09:09:30.681399 Epoch 50, Training loss 0.2323270957845791\n",
      "2021-10-24 09:09:37.314636 Epoch 60, Training loss 0.21558729516472785\n",
      "2021-10-24 09:09:43.827044 Epoch 70, Training loss 0.19935288389397274\n",
      "2021-10-24 09:09:50.530909 Epoch 80, Training loss 0.18338651917162974\n",
      "2021-10-24 09:09:57.206021 Epoch 90, Training loss 0.16800912659449183\n",
      "2021-10-24 09:10:03.789852 Epoch 100, Training loss 0.1533083135060444\n",
      "Accuracy train: 0.9345\n",
      "Accuracy val: 0.8875\n"
     ]
    }
   ],
   "source": [
    "# BaseLine\n",
    "model = Net().to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "  n_epochs = 100,\n",
    "  optimizer = optimizer,\n",
    "  model = model,\n",
    "  loss_fn = loss_fn,\n",
    "  train_loader = train_loader,\n",
    ")\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4b5fb0f-c0cc-424e-a575-04a7bce577fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-24 09:10:04.910695 Epoch 1, Training loss 0.5541238353890219\n",
      "2021-10-24 09:10:12.310755 Epoch 10, Training loss 0.314949399726406\n",
      "2021-10-24 09:10:20.346041 Epoch 20, Training loss 0.27511174132110205\n",
      "2021-10-24 09:10:28.477065 Epoch 30, Training loss 0.23893693246089728\n",
      "2021-10-24 09:10:36.620288 Epoch 40, Training loss 0.2095460427130104\n",
      "2021-10-24 09:10:44.682417 Epoch 50, Training loss 0.18427835960107244\n",
      "2021-10-24 09:10:52.726959 Epoch 60, Training loss 0.16028781512835225\n",
      "2021-10-24 09:11:01.037409 Epoch 70, Training loss 0.13716988222804039\n",
      "2021-10-24 09:11:09.394669 Epoch 80, Training loss 0.11557040690996084\n",
      "2021-10-24 09:11:17.489434 Epoch 90, Training loss 0.095670966775554\n",
      "2021-10-24 09:11:25.512568 Epoch 100, Training loss 0.07782927581411637\n",
      "Accuracy train: 0.9718\n",
      "Accuracy val: 0.8970\n"
     ]
    }
   ],
   "source": [
    "# Width\n",
    "model = NetWidth().to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "  n_epochs = 100,\n",
    "  optimizer = optimizer,\n",
    "  model = model,\n",
    "  loss_fn = loss_fn,\n",
    "  train_loader = train_loader,\n",
    ")\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5191645-0a36-4438-a05c-cca704a95940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-24 09:11:26.972561 Epoch 1, Training loss 0.6116031729112006\n",
      "2021-10-24 09:11:36.307936 Epoch 10, Training loss 0.35351358819159734\n",
      "2021-10-24 09:11:46.983132 Epoch 20, Training loss 0.32086193295800763\n",
      "2021-10-24 09:11:57.273923 Epoch 30, Training loss 0.2964062353797779\n",
      "2021-10-24 09:12:07.850323 Epoch 40, Training loss 0.2789325268025611\n",
      "2021-10-24 09:12:18.469925 Epoch 50, Training loss 0.26450393315713117\n",
      "2021-10-24 09:12:29.093945 Epoch 60, Training loss 0.2513328030420716\n",
      "2021-10-24 09:12:39.600604 Epoch 70, Training loss 0.23982535055868184\n",
      "2021-10-24 09:12:50.017184 Epoch 80, Training loss 0.22974915356393072\n",
      "2021-10-24 09:13:00.645942 Epoch 90, Training loss 0.22088077512516338\n",
      "2021-10-24 09:13:11.249288 Epoch 100, Training loss 0.2125840371201752\n",
      "Accuracy train: 0.9238\n",
      "Accuracy val: 0.8855\n"
     ]
    }
   ],
   "source": [
    "# L2-REG\n",
    "model = Net().to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop_l2reg(\n",
    "  n_epochs = 100,\n",
    "  optimizer = optimizer,\n",
    "  model = model,\n",
    "  loss_fn = loss_fn,\n",
    "  train_loader = train_loader,\n",
    ")\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab84b2fa-c8eb-40b3-a693-e3103f9d2ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-24 09:13:12.546927 Epoch 1, Training loss 0.5811816271702954\n",
      "2021-10-24 09:13:20.047160 Epoch 10, Training loss 0.38090168651501843\n",
      "2021-10-24 09:13:28.294411 Epoch 20, Training loss 0.34809785616246\n",
      "2021-10-24 09:13:36.512001 Epoch 30, Training loss 0.3335491590628958\n",
      "2021-10-24 09:13:44.962461 Epoch 40, Training loss 0.31835454844745104\n",
      "2021-10-24 09:13:53.363426 Epoch 50, Training loss 0.30043149962546717\n",
      "2021-10-24 09:14:01.674050 Epoch 60, Training loss 0.2903287018750124\n",
      "2021-10-24 09:14:10.099904 Epoch 70, Training loss 0.27566998931253034\n",
      "2021-10-24 09:14:18.399437 Epoch 80, Training loss 0.2647757158157932\n",
      "2021-10-24 09:14:26.914142 Epoch 90, Training loss 0.2560412506009363\n",
      "2021-10-24 09:14:35.314404 Epoch 100, Training loss 0.24476294200511495\n",
      "Accuracy train: 0.8949\n",
      "Accuracy val: 0.8725\n"
     ]
    }
   ],
   "source": [
    "# dropout\n",
    "model = NetDropout().to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "  n_epochs = 100,\n",
    "  optimizer = optimizer,\n",
    "  model = model,\n",
    "  loss_fn = loss_fn,\n",
    "  train_loader = train_loader,\n",
    ")\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "efce5339-41b9-49a4-aa66-01b22db2e629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-24 09:14:36.751522 Epoch 1, Training loss 0.4462037251633444\n",
      "2021-10-24 09:14:45.019397 Epoch 10, Training loss 0.2653114297872136\n",
      "2021-10-24 09:14:54.226660 Epoch 20, Training loss 0.20534340567459727\n",
      "2021-10-24 09:15:03.466422 Epoch 30, Training loss 0.15773218993548374\n",
      "2021-10-24 09:15:12.663165 Epoch 40, Training loss 0.11624795588765555\n",
      "2021-10-24 09:15:21.809689 Epoch 50, Training loss 0.08143674506313482\n",
      "2021-10-24 09:15:30.965873 Epoch 60, Training loss 0.05278764862068899\n",
      "2021-10-24 09:15:40.062880 Epoch 70, Training loss 0.033547059371830175\n",
      "2021-10-24 09:15:49.135889 Epoch 80, Training loss 0.0249861352691415\n",
      "2021-10-24 09:15:58.133812 Epoch 90, Training loss 0.01445921497111013\n",
      "2021-10-24 09:16:07.328517 Epoch 100, Training loss 0.00978637192172894\n",
      "Accuracy train: 0.9919\n",
      "Accuracy val: 0.8820\n"
     ]
    }
   ],
   "source": [
    "# batch-norm\n",
    "model = NetBatchNorm().to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "  n_epochs = 100,\n",
    "  optimizer = optimizer,\n",
    "  model = model,\n",
    "  loss_fn = loss_fn,\n",
    "  train_loader = train_loader,\n",
    ")\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5dd6e7b1-38a4-4a27-9e3e-e67f882c9aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-24 09:16:08.832640 Epoch 1, Training loss 0.6696571468547651\n",
      "2021-10-24 09:16:17.299201 Epoch 10, Training loss 0.3425118222737768\n",
      "2021-10-24 09:16:26.618532 Epoch 20, Training loss 0.2969878880651134\n",
      "2021-10-24 09:16:36.012895 Epoch 30, Training loss 0.2666872978020626\n",
      "2021-10-24 09:16:45.468434 Epoch 40, Training loss 0.24082016726587988\n",
      "2021-10-24 09:16:55.006942 Epoch 50, Training loss 0.2158025407297596\n",
      "2021-10-24 09:17:04.367028 Epoch 60, Training loss 0.19011007647985106\n",
      "2021-10-24 09:17:13.731457 Epoch 70, Training loss 0.16565029114294963\n",
      "2021-10-24 09:17:23.075122 Epoch 80, Training loss 0.13943742343764395\n",
      "2021-10-24 09:17:32.653569 Epoch 90, Training loss 0.11420408664211916\n",
      "2021-10-24 09:17:42.414246 Epoch 100, Training loss 0.09182678348129722\n",
      "Accuracy train: 0.9285\n",
      "Accuracy val: 0.8800\n"
     ]
    }
   ],
   "source": [
    "# depth\n",
    "model = NetDepth().to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "  n_epochs = 100,\n",
    "  optimizer = optimizer,\n",
    "  model = model,\n",
    "  loss_fn = loss_fn,\n",
    "  train_loader = train_loader,\n",
    ")\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50cf69a7-0309-4bc0-be5a-24202e62b6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-24 09:17:43.980826 Epoch 1, Training loss 0.6366562687667312\n",
      "2021-10-24 09:17:52.969054 Epoch 10, Training loss 0.33136845014657185\n",
      "2021-10-24 09:18:02.881987 Epoch 20, Training loss 0.29083979101317703\n",
      "2021-10-24 09:18:12.721063 Epoch 30, Training loss 0.25499793365123163\n",
      "2021-10-24 09:18:22.706643 Epoch 40, Training loss 0.22438272155204397\n",
      "2021-10-24 09:18:32.706656 Epoch 50, Training loss 0.19872367832880872\n",
      "2021-10-24 09:18:42.619525 Epoch 60, Training loss 0.17619514536515923\n",
      "2021-10-24 09:18:52.567528 Epoch 70, Training loss 0.15467868059588846\n",
      "2021-10-24 09:19:02.469907 Epoch 80, Training loss 0.13344264991439073\n",
      "2021-10-24 09:19:12.171441 Epoch 90, Training loss 0.11253324694409492\n",
      "2021-10-24 09:19:21.641279 Epoch 100, Training loss 0.09167177724847748\n",
      "Accuracy train: 0.9695\n",
      "Accuracy val: 0.9065\n"
     ]
    }
   ],
   "source": [
    "# RES\n",
    "model = NetRes().to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "  n_epochs = 100,\n",
    "  optimizer = optimizer,\n",
    "  model = model,\n",
    "  loss_fn = loss_fn,\n",
    "  train_loader = train_loader,\n",
    ")\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "223bc0fc-d10c-4885-9b97-66335c2dbae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-24 09:19:26.151268 Epoch 1, Training loss 0.5274993185025112\n",
      "2021-10-24 09:20:01.733519 Epoch 10, Training loss 0.22032921694836038\n",
      "2021-10-24 09:20:41.181698 Epoch 20, Training loss 0.11168192304480987\n",
      "2021-10-24 09:21:20.635993 Epoch 30, Training loss 0.07389530469515142\n",
      "2021-10-24 09:22:00.176135 Epoch 40, Training loss 0.03434919258045733\n",
      "2021-10-24 09:22:39.794605 Epoch 50, Training loss 0.05781054924165083\n",
      "2021-10-24 09:23:19.477472 Epoch 60, Training loss 0.027413468958089236\n",
      "2021-10-24 09:23:59.217434 Epoch 70, Training loss 0.0025167885399757215\n",
      "2021-10-24 09:24:38.856528 Epoch 80, Training loss 0.0014126229943013542\n",
      "2021-10-24 09:25:18.369825 Epoch 90, Training loss 0.0007876235621245015\n",
      "2021-10-24 09:25:57.878408 Epoch 100, Training loss 0.0006111824529230295\n",
      "Accuracy train: 0.9997\n",
      "Accuracy val: 0.8945\n"
     ]
    }
   ],
   "source": [
    "# RES-DEEP\n",
    "model = NetResDeep().to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "  n_epochs = 100,\n",
    "  optimizer = optimizer,\n",
    "  model = model,\n",
    "  loss_fn = loss_fn,\n",
    "  train_loader = train_loader,\n",
    ")\n",
    "validate(model, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
